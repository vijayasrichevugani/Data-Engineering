{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a061b9c",
   "metadata": {},
   "source": [
    "Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac25e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sqa\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import win32com.client\n",
    "import getpass\n",
    "import requests\n",
    "import zipfile,shutil\n",
    "import logging\n",
    "import pyodbc\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "from threading import Thread\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d4f32",
   "metadata": {},
   "source": [
    "Get the current date to track the data loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24090f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datetime.now()\n",
    "date=x.strftime(\"%d\")+\"-\"+x.strftime(\"%m\")+\"-\"+x.strftime(\"%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2ee13",
   "metadata": {},
   "source": [
    "Create the logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level = logging.INFO,\n",
    "    format = \"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers[\n",
    "        logging.FileHandler(\"debug.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a53c2a",
   "metadata": {},
   "source": [
    "Connect to Database and create functions to load data to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ef3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConnStr = \"DRIVER = {Provide your driver name };TrustServerCertificate = yes;Authentication=ActiveDirectoryIntegrated;SERVER = GiveyourServernamewithport;DATABASE = DBNAME\"\n",
    "def ConnectToDB(ConnStr):\n",
    "    params = urllib.parse.quote_plus(ConnStr)\n",
    "    engine = sqa.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "    cnxn = engine.connect()\n",
    "    cnxn.fast_executemany = True\n",
    "    return cnxn\n",
    "\n",
    "def LoadToSQL(tbl,cnxn,chunk):\n",
    "    chunk.to_sql(name = tbl,con = cnxn,schema = 'dbo',if_exists = 'append',index = False, index_Label=None,chunksize = 100000)\n",
    "    \n",
    "def CreateTargetTable(tbl,cnxn,chunk):\n",
    "    chunk.to_sql(name = tbl,con = cnxn;schema = 'dbo',if_exist = 'replace',index = False,index_Label = None,chunksize =100000,dtype  = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5825b2",
   "metadata": {},
   "source": [
    "Function to Load huge data to SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParallelLoad(df,TargetTable,ConnString,func,ThreadLimit = 16):\n",
    "    connections = []\n",
    "    for i in range(0,ThreadLimit,1):\n",
    "        connections.append(ConnectToDB(ConnString))\n",
    "    threads=[]\n",
    "    StepSize = int(df.shape[0]/ThreadLimit)\n",
    "    for i in range(0,ThreadLimit):\n",
    "        process = Thread(target=func,args = [TargetTable,connections[i],df[i*StepSize:(i*StepSize)+StepSize]])\n",
    "        process.start()\n",
    "        threads.append(process)\n",
    "    for process in threads:\n",
    "        process.join()\n",
    "    threads = []\n",
    "    if (StepSize*ThreadLimit)!= df.shape[0]:\n",
    "        process = Thread(target=func,args = [TargetTable,connection[0],df(StepSize*ThreadLimit):df.shape[0]])\n",
    "        process.start()\n",
    "        threads.append(process)\n",
    "    for process in threads:\n",
    "        process.join()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d124bcc1",
   "metadata": {},
   "source": [
    "targetdir - Directory where your zip files are present.\n",
    "ProcessedDir - Directory where the processed zip files will be moved.\n",
    "zippedFiles - List of Zip files in the directory.\n",
    "binaryFiles - List of Unzipped files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdir = 'Provideyourfilepath/whichneedstobe/loadedtoSQL'\n",
    "ProcessedDir = targetdir+\"Processed\"\n",
    "zippedFiles = glob.glob(targetdir+'*zip',recursive = True)\n",
    "binaryFiles = glob.glob(targetdir+'**/*'+'*xlsb',recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df546a",
   "metadata": {},
   "source": [
    "Printing the zipped files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a53d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(zippedFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667d1a9d",
   "metadata": {},
   "source": [
    "Printing the unzipped files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(binaryFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d70373",
   "metadata": {},
   "source": [
    "Exisiting excel files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74129e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "existingfilesList = []\n",
    "for files in binaryFiles:\n",
    "    fileNameList = files.split('\\\\')\n",
    "    for name in fileNameList:\n",
    "        if 'xlsb' in name:\n",
    "            existingfilesList.append(name.replace(\".xlsb\",\"\"))\n",
    "            break\n",
    "logging.info(existingfilesList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b9ec8",
   "metadata": {},
   "source": [
    "Unzip the zip files and move the zip files to processed directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6965dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fl in zippedFiles:\n",
    "    f = fl.split(\"\\\\\").pop().replace(\".zip\",\"\")\n",
    "    if f not in exisitngfilesList:\n",
    "        logging.info(f)\n",
    "        if(zipfile.is_zipfile(fl) and fl.split(\".\").pop()==\"zip\"):\n",
    "            with zipfile.ZipFile(fl,'r') as m:\n",
    "                m.extractall(path = targetdir+'/'+f)\n",
    "    try:\n",
    "        shutil.move(src = fl,dst = ProcessedDir)\n",
    "        logging.info('Moved: '+fl)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f1b14",
   "metadata": {},
   "source": [
    "Get all the excel files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedFiles = glob.glob(targetdir+'**/*'+'*.xlsb',recursive=True)\n",
    "logging.info(updatedFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee43a8",
   "metadata": {},
   "source": [
    "Function to create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384accee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTable(df,tableName):\n",
    "    columnName = list(df.column.values)\n",
    "    createTableStatement = 'CREATE TABLE '+tableName + ' ('\n",
    "    for i in range(len(columnName)):\n",
    "        createTableStatement = createTableStatement+ '\\n'+\"[\"+columnName[i]+\"]\"+' '+'NVARCHAR(max) NULL'+','\n",
    "    createTableStatement = createTableStatement[:-1]+')'\n",
    "    print(\"createTableStatement \",createTableStatement)\n",
    "    conn = pyodbc.connect('DRIVER = {Your Driver Name};'\n",
    "                         'TrustServerCertificate = yes;'\n",
    "                         'Authentication=ActiveDirectoryIntegrated;'\n",
    "                          'SERVER = GiveyourServername:port;'\n",
    "                          'DATABASE = DBNAME')\n",
    "    cursor = conn.cursor()\n",
    "    dropStatement = 'DROP TABLE IF EXIST dbo.'+tableName\n",
    "    cursor.execute(dropStatement)\n",
    "    cursor.execute(createTableStatement)\n",
    "    logging.info(tableName+\"Table Created Successfully.\")\n",
    "    #commit your changes in database\n",
    "    conn.commit()\n",
    "    #close the connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f150219",
   "metadata": {},
   "source": [
    "Create a sequence in the database and get the next value from the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18380f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = ConnectToDB(ConnString)\n",
    "sql = '''select next value for [dbo].[YourSequenceName]'''\n",
    "data = pd.read_sql(sql,conn)\n",
    "sequence = 0\n",
    "for i,j in data.iterrows():\n",
    "    sequence = j\n",
    "print(sequence[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75d523",
   "metadata": {},
   "source": [
    "check the current count of the data in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42336792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRowcount(tableName):\n",
    "    conn = ConnectToDB(ConnString)\n",
    "    try:\n",
    "        rowcount = conn.execute(\"select count(*) from [\"+tableName+\"]\").scalar()\n",
    "    except:\n",
    "        rowcount = -1\n",
    "    return rowcount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6aba76",
   "metadata": {},
   "source": [
    "check the current count of data in the table for a specific excel file that is being loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bed0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSpecificRowcount(parameter,tableName):\n",
    "    conn = ConnectToDB(ConnString)\n",
    "    try:\n",
    "        rowcount = conn.execute(\"select count(*)  from [\"+tableName+\"] where SourceFile= '\"+parameter+\"'\").scalar()\n",
    "    except:\n",
    "        rowcount = -1\n",
    "    return rowcount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8df9cb",
   "metadata": {},
   "source": [
    "Delete the data from table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteStatement(parameter,tableName):\n",
    "    conn = ConnectToDB(ConnString)\n",
    "    rowcount = conn.execute(\"DELETE FROM [\"+tableName+\"] where SourceFile= '\"+parameter+\"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb044906",
   "metadata": {},
   "source": [
    "Provide the table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0123a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "YourTableName = 'YourTableName'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9401e164",
   "metadata": {},
   "source": [
    "Create the RunLogTable in the database to track the data loading.\n",
    "pattern name is the common value for all the excels in the directory.\n",
    "For example, the files you want to load in the table have 'Google'in the name then 'Google' can be your pattern name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962426bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logInformation(fileName,message,status):\n",
    "    conn = pyodbc.connect('DRIVER = {Provide your driver name };'\n",
    "                          'TrustServerCertificate = yes;'\n",
    "                          'Authentication=ActiveDirectoryIntegrated;'\n",
    "                          'SERVER = GiveyourServernamewithport;'\n",
    "                          'DATABASE = DBNAME')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"INSERT INTO RunLogTable(run_id,source,source_file_name,message,status,created_date) VALUES (?,?,?,?,?,?)\",(int(sequence[0]),'PatternName',fileName,message,status,datetime.now()))\n",
    "    logging.info(tableName+\" Log Table Updated Successfully!\")\n",
    "    #commit your changes in the database\n",
    "    conn.commit()\n",
    "    #closing the connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c8283",
   "metadata": {},
   "source": [
    "Load the data to SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9639ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in UpdatedFiles:\n",
    "    MyRowCount = checkRowcount(YourTableName)\n",
    "    tableName = \"\"\n",
    "    if files not in binaryFiles:\n",
    "        failedCount =0\n",
    "        fileNameList=files.split('\\\\')\n",
    "        for name in fileNameList:\n",
    "            if 'xlsb' in name:\n",
    "                nameList = name.split(\" \")\n",
    "                if len(nameList)>0:\n",
    "                    for item in nameList:\n",
    "                        if 'PatternName' in item:\n",
    "                            tableName = item.replace(\".xlsb\",\"\")\n",
    "                            break\n",
    "                else:\n",
    "                    tableName =name.replace(\".xlsb\",\"\")\n",
    "                break\n",
    "        logging.info(\"Table Name: \"+tableName)\n",
    "        files = files.replace('\\\\','/')\n",
    "        df = pd.read_excel(files,engine = 'pyxlsb',sheet_name ='my_sheet',skiprows=0)\n",
    "        for col in df.columns:\n",
    "            if col.startswith('Unnamed'):\n",
    "                df.drop(col,axis=1,inplace=True)\n",
    "        df['SourceFile']=tableName\n",
    "        df['UploadDate']=date\n",
    "        if(MyRowCount==-1):\n",
    "            createTable(df,YourTableName)\n",
    "        try:\n",
    "            logInformation(tableName,\"Python: Data Upload Operation Started\",\"start\")\n",
    "            result = ParallelLoad(df,YourTableName,ConnString,LoadToSQL,16)\n",
    "            logging.info(result)\n",
    "            rowcount = checkSpecificRowcount(tableName,YourTableName)\n",
    "            if rowcount == df.shape[0]:\n",
    "                logInformation(tableName,\"Python: File has been uploaded successfully\",\"Success\")\n",
    "            else:\n",
    "                logInformation(tableName,\"Python: All rows have not been uploaded.\",\"Failure\")\n",
    "                raise Exception(\"All the rows have not been uploaded\")\n",
    "        except Exception as err:\n",
    "            if(failedCount <=5):\n",
    "                failedCount=failedCount+1\n",
    "                logInformation(tableName,\"Python Error: \"+str(err),\"Error\")\n",
    "                logging.exception(err)\n",
    "                logInformation(tableName,\"Python: Retrying Loading data\",\"Retry\")\n",
    "                logging.info(\"Retrying..\")\n",
    "                deleteStatement(tableName,YourTableName)\n",
    "                #createTable(df,tableName)\n",
    "                logInformation(tableName,\"Python: Data Upload Operation Started\",\"Start\")\n",
    "                result = ParallelLoad(df,YourTableName,ConnString,LoadToSQL,16)\n",
    "                logging.info(result)\n",
    "                logInformation(tableName,\"Python: File has been uploaded sucessfully.\",\"Success\")\n",
    "            else:\n",
    "                logInformation(tableName,\"Python: Operation has failed.\",\"Failure\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
